import os
import json
import datetime
import asyncio
from typing import Dict, List
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_community.tools import DuckDuckGoSearchRun
from models import MarketBriefingResponse, PortfolioResponse

# --- 1. ì„¤ì • ë° ë„êµ¬ ---
# ë¶„ì„ ì¼ê´€ì„±ì„ ìœ„í•´ seedë¥¼ ê³ ì •í•˜ê³ , ì°½ì˜ì„±(temperature)ì„ 0ìœ¼ë¡œ ì„¤ì •
llm = ChatOllama(model="gemma2:9b", temperature=0.0, format="json", seed=42)
search = DuckDuckGoSearchRun()

# [ë³€ê²½] ë¦¬í¬íŠ¸ë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œ ì„¤ì •
REPORT_DIR = "reports"
if not os.path.exists(REPORT_DIR):
    os.makedirs(REPORT_DIR)

# ì „ì—­ ì €ì¥ì†Œ (ë©”ëª¨ë¦¬)
DAILY_BRIEFING_DATA: Dict = {}        # ì˜¤ëŠ˜ì ë¦¬í¬íŠ¸ (ë©”ì¸ í™”ë©´ìš©)
WEEKLY_CONTEXT_SUMMARY: str = ""      # ìµœê·¼ 1ì£¼ì¼ ìš”ì•½ë³¸ (í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±ìš©)

# --- 2. í”„ë¡¬í”„íŠ¸ & ì²´ì¸ ì •ì˜ ---

# (A) ì‹œì¥ ë¦¬í¬íŠ¸ ë°œí–‰ìš© ì²´ì¸ (ë§¤ì¼ ìƒì„±ë˜ëŠ” ì¡°ê°„ ì‹ ë¬¸)
briefing_parser = JsonOutputParser(pydantic_object=MarketBriefingResponse)
briefing_prompt = ChatPromptTemplate.from_messages([
    ("system", """
    ë‹¹ì‹ ì€ ìˆ˜ì„ ê¸ˆìœµ ì‹œì¥ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ì œê³µëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë©”ì¸ ëŒ€ì‹œë³´ë“œì— ë„ìš¸ 'ì¼ì¼ ì‹œì¥ ë¦¬í¬íŠ¸'ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    
    [í•„ìˆ˜ ë¶„ì„ ëŒ€ìƒ - 11ê°œ GICS ì„¹í„° ì „ì²´]
    ë‹¤ìŒ 11ê°œ ì„¹í„°ì˜ ë™í–¥ì„ ë¹ ì§ì—†ì´ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤:
    1. Information Technology (ì •ë³´ê¸°ìˆ )
    2. Communication Services (ì»¤ë®¤ë‹ˆì¼€ì´ì…˜)
    3. Consumer Discretionary (ì„ì˜ì†Œë¹„ì¬)
    4. Consumer Staples (í•„ìˆ˜ì†Œë¹„ì¬)
    5. Energy (ì—ë„ˆì§€)
    6. Financials (ê¸ˆìœµ)
    7. Health Care (í—¬ìŠ¤ì¼€ì–´)
    8. Industrials (ì‚°ì—…ì¬)
    9. Materials (ì†Œì¬)
    10. Real Estate (ë¶€ë™ì‚°)
    11. Utilities (ìœ í‹¸ë¦¬í‹°)
    
    [ì‘ì„± ê·œì¹™]
    1. **macro_summary**: ê¸ˆë¦¬, ë¬¼ê°€, ì—°ì¤€ì˜ ì›€ì§ì„ ë“± ê±°ì‹œ ê²½ì œ ìƒí™©ì„ ì´ˆë³´ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
    2. **sectors - status**: 'Bullish' ê°™ì€ ì˜ì–´ ëŒ€ì‹ , **"ìƒìŠ¹ì„¸ (ì¢‹ìŒ)", "í•˜ë½ì„¸ (ì£¼ì˜)", "ë³´í•©ì„¸ (ì§€ì¼œë³´ëŠ” ì¤‘)"** ê³¼ ê°™ì´ ì§ê´€ì ì¸ í•œêµ­ì–´ë¡œ ì ìœ¼ì„¸ìš”.
    3. **sectors - summary**: ê° ì„¹í„°ì˜ ì´ìŠˆë¥¼ í•œêµ­ì–´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    
    {format_instructions}
    """),
    ("human", "{raw_news}")
])
briefing_chain = briefing_prompt | llm | briefing_parser

# (B) í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±ìš© ì²´ì¸ (â˜… 1ì£¼ì¼ ë°ì´í„° ë°˜ì˜ â˜…)
portfolio_parser = JsonOutputParser(pydantic_object=PortfolioResponse)
portfolio_prompt = ChatPromptTemplate.from_messages([
    ("system", """
    ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ 20ë…„ ê²½ë ¥ì˜ ETF ì „ë¬¸ í€ë“œë§¤ë‹ˆì €ì…ë‹ˆë‹¤.
    
    [í•µì‹¬ ëª©í‘œ]
    ì œê³µëœ [ìµœê·¼ 1ì£¼ì¼ê°„ì˜ ì‹œì¥ íë¦„]ê³¼ [ì‚¬ìš©ì í”„ë¡œí•„]ì„ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ìµœì í™”ëœ ë¯¸êµ­ ETF í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì œì•ˆí•˜ì‹­ì‹œì˜¤.
    
    [ìƒì„¸ ì§€ì¹¨]
    1. **ì‹œì¥ íë¦„ ë¶„ì„**: 
       - ì§€ë‚œ 1ì£¼ì¼ê°„ì˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ì‹œì¥ì´ ìƒìŠ¹ ì¶”ì„¸ì¸ì§€, í•˜ë½ ì¶”ì„¸ì¸ì§€, ê¸ˆë¦¬ ì´ìŠˆê°€ ì–´ë–»ê²Œ ë³€í•˜ê³  ìˆëŠ”ì§€ íŒŒì•…í•˜ì„¸ìš”.
       - íŠ¹íˆ **í˜„ì¬ ê¸ˆë¦¬ ìˆ˜ì¤€**ê³¼ **ì£¼ë„ ì„¹í„°ì˜ ë³€í™”**ë¥¼ ì´ˆë³´ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
    
    2. **ì„±í–¥ë³„ ì „ëµ ìˆ˜ë¦½**: 
       - ê³µê²©í˜•: TQQQ, SOXL ë“± ë ˆë²„ë¦¬ì§€ ë° ì£¼ë„ ì„¹í„°(AI/ë°˜ë„ì²´ ë“±) ë¹„ì¤‘ í™•ëŒ€.
       - ì¤‘ë¦½/ì•ˆì •í˜•: VOO, SCHD, TLT ë“± ì‹œì¥ì§€ìˆ˜ ë° ë°°ë‹¹/ì±„ê¶Œ ìœ„ì£¼ êµ¬ì„±.
    
    3. **ì„¹í„° ë¡œí…Œì´ì…˜ ë°˜ì˜**: 
       - ìµœê·¼ 1ì£¼ì¼ê°„ ì§€ì†ì ìœ¼ë¡œ ê°•ì„¸ë¥¼ ë³´ì´ëŠ” ì„¹í„°ë¥¼ í¬íŠ¸í´ë¦¬ì˜¤ì— ì ê·¹ ë°˜ì˜í•˜ì„¸ìš”.

    4. **ONLY ETF (ì ˆëŒ€ ê·œì¹™)**: 
       - í¬íŠ¸í´ë¦¬ì˜¤ëŠ” **100% ë¯¸êµ­ ìƒì¥ ETF**ë¡œë§Œ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤. (ê°œë³„ ì£¼ì‹ ì ˆëŒ€ ê¸ˆì§€)

    5. **ë¹„ì¤‘ ì„¤ì • ê·œì¹™ (Rounding)**: 
       - ëª¨ë“  ì¢…ëª©ì˜ ë¹„ì¤‘ì€ **5% ë˜ëŠ” 10% ë‹¨ìœ„**ë¡œ ì„¤ì •í•˜ì„¸ìš”. (í•©ê³„ 100%)

    6. **ì¶œë ¥ í˜•ì‹ (ê¸°ìˆ ì  ì œì•½)**: 
       - **ë°˜ë“œì‹œ ì§€ì •ëœ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.**
    
    {format_instructions}
    """),
    
    ("human", """
    [ìµœê·¼ 1ì£¼ì¼ê°„ì˜ ì‹œì¥ ë¦¬í¬íŠ¸ ìš”ì•½ (Context)]
    {weekly_context}
    
    [ì‚¬ìš©ì í”„ë¡œí•„]
    ë‚˜ì´: {age}, ìì‚°: {seed_money}, ì„±í–¥: {risk_tolerance}, ëª©í‘œ: {goal}
    """)
])
portfolio_chain = portfolio_prompt | llm | portfolio_parser

# --- 3. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ í•¨ìˆ˜ ---

async def fetch_news_sequentially():
    news_data = {}
    try:
        print("ğŸ” [Service] ê±°ì‹œê²½ì œ ë‰´ìŠ¤ ê²€ìƒ‰...")
        news_data['macro'] = search.invoke("US Fed interest rate inflation CPI PPI economy news today summary")
        await asyncio.sleep(2) # ë°´ ë°©ì§€

        print("ğŸ” [Service] 11ê°œ ì„¹í„° ì „ë°˜ ë‰´ìŠ¤ ê²€ìƒ‰...")
        news_data['sector'] = search.invoke("US stock market S&P 500 11 sectors performance winners and losers today summary")
        await asyncio.sleep(2) # ë°´ ë°©ì§€

        print("ğŸ” [Service] ë¦¬ìŠ¤í¬ ë‰´ìŠ¤ ê²€ìƒ‰...")
        news_data['risk'] = search.invoke("US stock market geopolitical risk war oil price fear and greed index")
        
        return f"""
        [ê±°ì‹œê²½ì œ ë‰´ìŠ¤]: {news_data['macro']}
        [ì„¹í„°ë³„ ë‰´ìŠ¤]: {news_data['sector']}
        [ì‹œì¥ ë¦¬ìŠ¤í¬]: {news_data['risk']}
        """
    except Exception as e:
        print(f"âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return None

def load_weekly_reports_summary():
    """
    ìµœê·¼ 7ì¼ê°„ì˜ ë¦¬í¬íŠ¸ íŒŒì¼ë“¤ì„ ì½ì–´ì„œ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    """
    summary_text = ""
    today = datetime.date.today()
    
    print("ğŸ“… [Service] ìµœê·¼ 1ì£¼ì¼ê°„ì˜ ë°ì´í„°(ì´ìœ  í¬í•¨) ë¡œë“œ ì¤‘...")
    
    # ì˜¤ëŠ˜ë¶€í„° ê³¼ê±° 7ì¼ê°„ ì—­ìˆœìœ¼ë¡œ í™•ì¸
    found_count = 0
    for i in range(7):
        target_date = today - datetime.timedelta(days=i)
        filename = f"{REPORT_DIR}/market_report_{target_date.isoformat()}.json"
        
        if os.path.exists(filename):
            try:
                with open(filename, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    
                summary_text += f"\n=== [ë‚ ì§œ: {data['date']}] ===\n"
                summary_text += f"- ê±°ì‹œê²½ì œ: {data.get('macro_summary', 'ë‚´ìš© ì—†ìŒ')}\n"
                
                # ì˜ˆ: "Technology: ìƒìŠ¹ì„¸ (AI ë°˜ë„ì²´ ì‹¤ì  í˜¸ì¡°ë¡œ ê¸‰ë“±)"
                sectors_details = []
                for s in data.get('sectors', []):
                    # ìƒíƒœì—ì„œ ê´„í˜¸ ë“± ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±° (ê¹”ë”í•˜ê²Œ)
                    short_status = s['status'].split('(')[0].strip() 
                    
                    # "ì„¹í„°ëª…: ìƒíƒœ (ì´ìœ )" í˜•ì‹ìœ¼ë¡œ ì¡°í•©
                    line = f"{s['name']}: {short_status} ({s.get('summary', 'ì´ìœ  ì—†ìŒ')})"
                    sectors_details.append(line)
                
                # ê°€ë…ì„±ì„ ìœ„í•´ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°
                summary_text += "- ì„¹í„° ìƒì„¸:\n" + "\n".join([f"  * {line}" for line in sectors_details]) + "\n"
                
                found_count += 1
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({filename}): {e}")
    
    if found_count == 0:
        return "ìµœê·¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ë°ì´í„°ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤."
        
    return summary_text

async def publish_daily_report():
    print("ğŸ“° [Service] ì‹œì¥ ë°ì´í„° í™•ì¸ ë° ì£¼ê°„ ë¶„ì„ ì‹œì‘...")
    global DAILY_BRIEFING_DATA
    global WEEKLY_CONTEXT_SUMMARY
    
    today_str = datetime.date.today().isoformat()
    today_filename = f"{REPORT_DIR}/market_report_{today_str}.json"

    # 1. [ì˜¤ëŠ˜] ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸ (ìºì‹±)
    if os.path.exists(today_filename):
        try:
            with open(today_filename, "r", encoding="utf-8") as f:
                saved_data = json.load(f)
            print(f"âœ… [Cache] ì˜¤ëŠ˜({today_str}) ë¦¬í¬íŠ¸ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
            DAILY_BRIEFING_DATA = saved_data
        except Exception:
            pass # ì½ê¸° ì‹¤íŒ¨í•˜ë©´ ìƒˆë¡œ ìƒì„±
    
    # 2. [ì˜¤ëŠ˜] ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if not DAILY_BRIEFING_DATA:
        print(f"ğŸš€ [New] {today_str} ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘...")
        raw_news = await fetch_news_sequentially()
        
        if raw_news:
            try:
                print("ğŸ§  [Service] AI ë¶„ì„ ì¤‘...")
                report = briefing_chain.invoke({
                    "raw_news": raw_news,
                    "format_instructions": briefing_parser.get_format_instructions()
                })
                report["date"] = today_str
                
                # ë‚ ì§œê°€ í¬í•¨ëœ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
                with open(today_filename, "w", encoding="utf-8") as f:
                    json.dump(report, f, ensure_ascii=False, indent=2)
                    
                DAILY_BRIEFING_DATA = report
                print("âœ… ì˜¤ëŠ˜ì˜ ë¦¬í¬íŠ¸ ë°œí–‰ ë° ì €ì¥ ì™„ë£Œ.")
            except Exception as e:
                print(f"âš ï¸ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
                DAILY_BRIEFING_DATA = {}
        else:
            print("âš ï¸ ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ.")

    # 3. [ì£¼ê°„] ìµœê·¼ 7ì¼ì¹˜ ë°ì´í„°ë¥¼ ëª¨ì•„ì„œ í¬íŠ¸í´ë¦¬ì˜¤ìš© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    #    (ì˜¤ëŠ˜ ë°ì´í„° ìƒì„± í›„ ì‹¤í–‰í•´ì•¼ ì˜¤ëŠ˜ ë‚´ìš©ê¹Œì§€ í¬í•¨ë¨)
    WEEKLY_CONTEXT_SUMMARY = load_weekly_reports_summary()
    print("âœ… ì£¼ê°„ íŠ¸ë Œë“œ ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ.")


def get_briefing_data():
    return DAILY_BRIEFING_DATA

def generate_portfolio_logic(request):
    # í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„± ì‹œì—ëŠ” 'WEEKLY_CONTEXT_SUMMARY'ë¥¼ ì‚¬ìš©
    # ë§Œì•½ ë°ì´í„°ê°€ ë¹„ì–´ìˆë‹¤ë©´ ë°©ì–´ ë¡œì§
    context = WEEKLY_CONTEXT_SUMMARY
    if not context:
        context = "ë°ì´í„° ë¶€ì¡±. í˜„ì¬ ì‹œì¥ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

    print(f"ğŸ” [Service] í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„± ìš”ì²­ (ì„±í–¥: {request.risk_tolerance})")
    
    return portfolio_chain.invoke({
        "weekly_context": context,
        "age": request.age,
        "seed_money": request.seed_money,
        "risk_tolerance": request.risk_tolerance,
        "goal": request.goal,
        "format_instructions": portfolio_parser.get_format_instructions()
    })